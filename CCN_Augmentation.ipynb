{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiNUcL4SmGfp"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhIF2vrpmLWm"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddNZJl6smOKo"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XqvTdKhmbWq",
        "outputId": "2eab3878-66ed-4367-e9c4-65fa9bcbd1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 808M/812M [00:03<00:00, 237MB/s]\n",
            "100% 812M/812M [00:03<00:00, 236MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1W9TTh3qx3o"
      },
      "outputs": [],
      "source": [
        "!unzip -qq dogs-vs-cats.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TAtUwThX0qf"
      },
      "outputs": [],
      "source": [
        "!unzip -qq test1.zip\n",
        "!unzip -qq train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pi2zupnns4Y"
      },
      "outputs": [],
      "source": [
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj87NOQuoQEH"
      },
      "outputs": [],
      "source": [
        "def make_subset(subset_name, start_index, end_index):\n",
        "  for category in (\"cat\", \"dog\"):\n",
        "    dir = new_base_dir / subset_name / category\n",
        "    os.makedirs(dir)\n",
        "    fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "    for fname in fnames:\n",
        "      shutil.copyfile(src=original_dir / fname,dst=dir / fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1WgbNXRoTeK"
      },
      "outputs": [],
      "source": [
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PVtr1TxAjnRd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10QiYISSpOLr"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtjhwXSlYsdX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpJhpPY9YjDX"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHGiqdmGYtjI",
        "outputId": "89dc020e-0924-4e6f-ac13-5846f883850b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "train_dataset = image_dataset_from_directory(\n",
        "                                              new_base_dir / \"train\",\n",
        "                                              image_size=(180, 180),\n",
        "                                              batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "                                              new_base_dir / \"validation\",\n",
        "                                              image_size=(180, 180),\n",
        "                                              batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "                                              new_base_dir / \"test\",\n",
        "                                              image_size=(180, 180),\n",
        "                                              batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB2IRMF6ZCw_"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(filepath=\"convnet_from_scratch.keras\",save_best_only=True,monitor=\"val_loss\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R81aKjAiaDWp",
        "outputId": "a184d3be-0ed8-476a-de57-ee0fc5c9f987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 4s/step - accuracy: 0.5108 - loss: 0.9008 - val_accuracy: 0.5000 - val_loss: 0.7043\n",
            "Epoch 2/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 4s/step - accuracy: 0.5083 - loss: 0.6951 - val_accuracy: 0.5020 - val_loss: 0.6927\n",
            "Epoch 3/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 3s/step - accuracy: 0.5306 - loss: 0.6949 - val_accuracy: 0.5340 - val_loss: 0.6769\n",
            "Epoch 4/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 3s/step - accuracy: 0.5922 - loss: 0.6715 - val_accuracy: 0.6460 - val_loss: 0.6169\n",
            "Epoch 5/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 4s/step - accuracy: 0.6323 - loss: 0.6356 - val_accuracy: 0.5860 - val_loss: 0.7020\n",
            "Epoch 6/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 3s/step - accuracy: 0.6766 - loss: 0.6239 - val_accuracy: 0.6520 - val_loss: 0.6364\n",
            "Epoch 7/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 3s/step - accuracy: 0.7183 - loss: 0.5549 - val_accuracy: 0.6750 - val_loss: 0.5863\n",
            "Epoch 8/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 4s/step - accuracy: 0.7445 - loss: 0.5288 - val_accuracy: 0.7290 - val_loss: 0.5578\n",
            "Epoch 9/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 4s/step - accuracy: 0.7778 - loss: 0.4704 - val_accuracy: 0.6170 - val_loss: 0.8613\n",
            "Epoch 10/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 4s/step - accuracy: 0.7675 - loss: 0.4744 - val_accuracy: 0.6890 - val_loss: 0.6994\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_dataset,epochs=10,validation_data=validation_dataset,callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoLSUiVUaKx3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}